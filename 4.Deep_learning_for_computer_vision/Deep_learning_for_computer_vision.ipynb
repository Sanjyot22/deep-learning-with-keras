{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to convnets\n",
    "![title](./pics/intro-pic.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "\n",
    "# keras imports \n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# utility functions\n",
    "import os\n",
    "import sys\n",
    "%matplotlib inline\n",
    "os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))))\n",
    "from utility.utils import utils\n",
    "utility_obj = utils()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating a small convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model architecture developement\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a classifier on top of the convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our convnet on MNIST images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_train shape: (60000, 28, 28, 1)\n",
      "input_test shape: (10000, 28, 28, 1) \n",
      "\n",
      "visualizing mnist data samples..\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mnist data lables\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "Starting model training..\n",
      "\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0153 - acc: 0.9955\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0116 - acc: 0.9966\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0087 - acc: 0.9972\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0081 - acc: 0.9975\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0079 - acc: 0.9978\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0066 - acc: 0.9982\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0063 - acc: 0.9984\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0048 - acc: 0.9987\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0042 - acc: 0.9988\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0055 - acc: 0.9986\n",
      "10000/10000 [==============================] - 1s 60us/step\n"
     ]
    }
   ],
   "source": [
    "# loading the mnist dataset\n",
    "(train_images_, train_labels), (test_images_, test_labels) = mnist.load_data()\n",
    "train_images = train_images_.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images_.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# data understanding\n",
    "print('input_train shape:', train_images.shape)\n",
    "print('input_test shape:', test_images.shape, \"\\n\")\n",
    "\n",
    "print (\"visualizing mnist data samples..\")\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(10,5))\n",
    "axarr[0].set_title('digit-5')\n",
    "axarr[0].imshow(train_images_[0])\n",
    "axarr[1].set_title('digit-7')\n",
    "axarr[1].imshow(test_images_[0])\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print (\"\\nmnist data lables\")\n",
    "print (train_labels[:2])\n",
    "print (\"\\nStarting model training..\\n\")\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_images, train_labels, epochs=10, batch_size=64)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting model training results\n",
    "utility_obj.plot_training_history(history.history, plot_val=False)\n",
    "print (\"Final accuracy on evaluation data: {}%\".format(round(test_acc,2)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pre-trained convnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./pics/conv_pre_training.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import sys\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "\n",
    "# keras imports \n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.datasets import mnist\n",
    "from keras.applications import VGG16\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# utility functions\n",
    "import os\n",
    "import sys\n",
    "%matplotlib inline\n",
    "os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))))\n",
    "from utility.utils import utils\n",
    "utility_obj = utils()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the VGG16 convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features using the pre-trained convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# The path to the directory where the original\n",
    "# dataset was uncompressed\n",
    "dir_path =  os.getcwd()\n",
    "base_dir = dir_path + '/cats_and_dogs_small'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    i =0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "            features_batch = conv_base.predict(inputs_batch)\n",
    "            features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "            labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "            i += 1\n",
    "            if i * batch_size >= sample_count:\n",
    "                # Note that since generators yield data indefinitely in a loop,\n",
    "                # we must `break` after every image has been seen once.\n",
    "                break\n",
    "    return features, labels\n",
    "train_features, train_labels = extract_features(train_dir, 2000)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "test_features, test_labels = extract_features(test_dir, 1000)\n",
    "train_features = np.reshape(train_features, (2000, 4 * 4 * 512))\n",
    "validation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\n",
    "test_features = np.reshape(test_features, (1000, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the feature vectors to train dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 1s 436us/step - loss: 0.6084 - acc: 0.6555 - val_loss: 0.4373 - val_acc: 0.8420\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 1s 271us/step - loss: 0.4333 - acc: 0.8090 - val_loss: 0.3580 - val_acc: 0.8600\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 1s 276us/step - loss: 0.3475 - acc: 0.8580 - val_loss: 0.3163 - val_acc: 0.8790\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 1s 272us/step - loss: 0.3141 - acc: 0.8685 - val_loss: 0.3072 - val_acc: 0.8870\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 1s 277us/step - loss: 0.2842 - acc: 0.8815 - val_loss: 0.2782 - val_acc: 0.8870\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 1s 276us/step - loss: 0.2615 - acc: 0.8955 - val_loss: 0.2710 - val_acc: 0.8900\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 1s 274us/step - loss: 0.2401 - acc: 0.9100 - val_loss: 0.2614 - val_acc: 0.8990\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 1s 276us/step - loss: 0.2371 - acc: 0.9075 - val_loss: 0.2636 - val_acc: 0.8920\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 1s 274us/step - loss: 0.2193 - acc: 0.9205 - val_loss: 0.2517 - val_acc: 0.8970\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 1s 269us/step - loss: 0.2118 - acc: 0.9140 - val_loss: 0.2474 - val_acc: 0.9010\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 1s 269us/step - loss: 0.1942 - acc: 0.9295 - val_loss: 0.2465 - val_acc: 0.9030\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 1s 276us/step - loss: 0.1827 - acc: 0.9350 - val_loss: 0.2423 - val_acc: 0.9050\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 1s 268us/step - loss: 0.1717 - acc: 0.9375 - val_loss: 0.2513 - val_acc: 0.9020\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 1s 274us/step - loss: 0.1688 - acc: 0.9395 - val_loss: 0.2464 - val_acc: 0.9030\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 1s 270us/step - loss: 0.1599 - acc: 0.9430 - val_loss: 0.2388 - val_acc: 0.9060\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 1s 274us/step - loss: 0.1511 - acc: 0.9490 - val_loss: 0.2425 - val_acc: 0.9050\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 1s 265us/step - loss: 0.1444 - acc: 0.9505 - val_loss: 0.2373 - val_acc: 0.9030\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 1s 275us/step - loss: 0.1399 - acc: 0.9535 - val_loss: 0.2385 - val_acc: 0.9030\n",
      "Epoch 19/30\n",
      "2000/2000 [==============================] - 1s 272us/step - loss: 0.1326 - acc: 0.9550 - val_loss: 0.2363 - val_acc: 0.9080\n",
      "Epoch 20/30\n",
      "2000/2000 [==============================] - 1s 271us/step - loss: 0.1281 - acc: 0.9565 - val_loss: 0.2382 - val_acc: 0.9050\n",
      "Epoch 21/30\n",
      "2000/2000 [==============================] - 1s 276us/step - loss: 0.1289 - acc: 0.9575 - val_loss: 0.2354 - val_acc: 0.9030\n",
      "Epoch 22/30\n",
      "2000/2000 [==============================] - 1s 276us/step - loss: 0.1171 - acc: 0.9575 - val_loss: 0.2359 - val_acc: 0.9040\n",
      "Epoch 23/30\n",
      "2000/2000 [==============================] - 1s 274us/step - loss: 0.1122 - acc: 0.9670 - val_loss: 0.2412 - val_acc: 0.9060\n",
      "Epoch 24/30\n",
      "2000/2000 [==============================] - 1s 271us/step - loss: 0.1072 - acc: 0.9625 - val_loss: 0.2435 - val_acc: 0.9050\n",
      "Epoch 25/30\n",
      "2000/2000 [==============================] - 1s 269us/step - loss: 0.1019 - acc: 0.9735 - val_loss: 0.2381 - val_acc: 0.9030\n",
      "Epoch 26/30\n",
      "2000/2000 [==============================] - 1s 274us/step - loss: 0.1000 - acc: 0.9670 - val_loss: 0.2433 - val_acc: 0.9040\n",
      "Epoch 27/30\n",
      "2000/2000 [==============================] - 1s 270us/step - loss: 0.0952 - acc: 0.9700 - val_loss: 0.2416 - val_acc: 0.9030\n",
      "Epoch 28/30\n",
      "2000/2000 [==============================] - 1s 266us/step - loss: 0.0923 - acc: 0.9725 - val_loss: 0.2414 - val_acc: 0.9010\n",
      "Epoch 29/30\n",
      "2000/2000 [==============================] - 1s 262us/step - loss: 0.0950 - acc: 0.9730 - val_loss: 0.2424 - val_acc: 0.9010\n",
      "Epoch 30/30\n",
      "2000/2000 [==============================] - 1s 273us/step - loss: 0.0857 - acc: 0.9710 - val_loss: 0.2412 - val_acc: 0.9000\n"
     ]
    }
   ],
   "source": [
    "# model architecture and training\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              loss='binary_crossentropy',metrics=['acc'])\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=30,\n",
    "                    batch_size=20,\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting model training results\n",
    "utility_obj.plot_training_history(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a densely-connected classifier on top of the convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 16,812,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freezing the convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base: 30\n",
      "This is the number of trainable weights after freezing the conv base: 4\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights before freezing the conv base:', len(model.trainable_weights))\n",
    "conv_base.trainable = False\n",
    "print('This is the number of trainable weights after freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model end-to-end with a frozen convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 0.5752 - acc: 0.7105 - val_loss: 0.4396 - val_acc: 0.8230\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.4762 - acc: 0.7900 - val_loss: 0.3637 - val_acc: 0.8580\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.4128 - acc: 0.8215 - val_loss: 0.3541 - val_acc: 0.8490\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.4150 - acc: 0.8135 - val_loss: 0.3109 - val_acc: 0.8760\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.3825 - acc: 0.8300 - val_loss: 0.3044 - val_acc: 0.8770\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.3664 - acc: 0.8450 - val_loss: 0.2844 - val_acc: 0.8780\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.3512 - acc: 0.8525 - val_loss: 0.2746 - val_acc: 0.8880\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.3575 - acc: 0.8400 - val_loss: 0.2771 - val_acc: 0.8810\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.3460 - acc: 0.8490 - val_loss: 0.2755 - val_acc: 0.8850\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.3428 - acc: 0.8495 - val_loss: 0.2594 - val_acc: 0.8910\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.3322 - acc: 0.8615 - val_loss: 0.2583 - val_acc: 0.8980\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.3291 - acc: 0.8550 - val_loss: 0.2562 - val_acc: 0.8980\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.3155 - acc: 0.8635 - val_loss: 0.2546 - val_acc: 0.8970\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.3148 - acc: 0.8595 - val_loss: 0.2520 - val_acc: 0.9020\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.3109 - acc: 0.8600 - val_loss: 0.2481 - val_acc: 0.9000\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.3269 - acc: 0.8645 - val_loss: 0.2450 - val_acc: 0.9000\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.3045 - acc: 0.8680 - val_loss: 0.2414 - val_acc: 0.9000\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.3096 - acc: 0.8685 - val_loss: 0.2424 - val_acc: 0.9010\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.2911 - acc: 0.8750 - val_loss: 0.2412 - val_acc: 0.9010\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.3094 - acc: 0.8635 - val_loss: 0.2411 - val_acc: 0.9000\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.3032 - acc: 0.8700 - val_loss: 0.2417 - val_acc: 0.9030\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.2949 - acc: 0.8815 - val_loss: 0.2392 - val_acc: 0.9020\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.2980 - acc: 0.8735 - val_loss: 0.2366 - val_acc: 0.9040\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2896 - acc: 0.8815 - val_loss: 0.2450 - val_acc: 0.9020\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2918 - acc: 0.8690 - val_loss: 0.2392 - val_acc: 0.9040\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2968 - acc: 0.8705 - val_loss: 0.2380 - val_acc: 0.9010\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2731 - acc: 0.8885 - val_loss: 0.2360 - val_acc: 0.9020\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2896 - acc: 0.8855 - val_loss: 0.2385 - val_acc: 0.9050\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.2893 - acc: 0.8830 - val_loss: 0.2366 - val_acc: 0.9050\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.2844 - acc: 0.8790 - val_loss: 0.2425 - val_acc: 0.9080\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['acc'])\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting model training results\n",
    "utility_obj.plot_training_history(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freezing all layers up to a specific one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.2787 - acc: 0.8815 - val_loss: 0.2295 - val_acc: 0.9140\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.2782 - acc: 0.8835 - val_loss: 0.2443 - val_acc: 0.9100\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.2451 - acc: 0.8965 - val_loss: 0.2048 - val_acc: 0.9210\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2140 - acc: 0.9100 - val_loss: 0.1936 - val_acc: 0.9260\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.2251 - acc: 0.9095 - val_loss: 0.2170 - val_acc: 0.9210\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.2017 - acc: 0.9125 - val_loss: 0.2028 - val_acc: 0.9220\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.1751 - acc: 0.9295 - val_loss: 0.2185 - val_acc: 0.9160\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.1683 - acc: 0.9240 - val_loss: 0.2040 - val_acc: 0.9270\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.1633 - acc: 0.9345 - val_loss: 0.1909 - val_acc: 0.9320\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1631 - acc: 0.9315 - val_loss: 0.1991 - val_acc: 0.9280\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.1506 - acc: 0.9405 - val_loss: 0.1784 - val_acc: 0.9390\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.1552 - acc: 0.9420 - val_loss: 0.1779 - val_acc: 0.9340\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1278 - acc: 0.9465 - val_loss: 0.1926 - val_acc: 0.9260\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.1417 - acc: 0.9420 - val_loss: 0.1857 - val_acc: 0.9300\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.1231 - acc: 0.9470 - val_loss: 0.3014 - val_acc: 0.9000\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.1161 - acc: 0.9540 - val_loss: 0.1899 - val_acc: 0.9290\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.1071 - acc: 0.9600 - val_loss: 0.1701 - val_acc: 0.9410\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.1115 - acc: 0.9560 - val_loss: 0.2441 - val_acc: 0.9160\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.0993 - acc: 0.9625 - val_loss: 0.2377 - val_acc: 0.9150\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0925 - acc: 0.9600 - val_loss: 0.1971 - val_acc: 0.9300\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0970 - acc: 0.9600 - val_loss: 0.1998 - val_acc: 0.9260\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.0877 - acc: 0.9685 - val_loss: 0.1639 - val_acc: 0.9350\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0955 - acc: 0.9630 - val_loss: 0.2011 - val_acc: 0.9280\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0838 - acc: 0.9685 - val_loss: 0.2001 - val_acc: 0.9250\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0901 - acc: 0.9660 - val_loss: 0.2020 - val_acc: 0.9280\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.0693 - acc: 0.9730 - val_loss: 0.2217 - val_acc: 0.9210\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0715 - acc: 0.9720 - val_loss: 0.2120 - val_acc: 0.9360\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.0698 - acc: 0.9735 - val_loss: 0.1835 - val_acc: 0.9380\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.0797 - acc: 0.9670 - val_loss: 0.2001 - val_acc: 0.9310\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0747 - acc: 0.9770 - val_loss: 0.1972 - val_acc: 0.9250\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0608 - acc: 0.9735 - val_loss: 0.2180 - val_acc: 0.9310\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.0540 - acc: 0.9785 - val_loss: 0.2928 - val_acc: 0.9250\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0732 - acc: 0.9705 - val_loss: 0.2196 - val_acc: 0.9290\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.0689 - acc: 0.9745 - val_loss: 0.2245 - val_acc: 0.9320\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0529 - acc: 0.9815 - val_loss: 0.2261 - val_acc: 0.9280\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.0647 - acc: 0.9775 - val_loss: 0.1982 - val_acc: 0.9350\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0528 - acc: 0.9810 - val_loss: 0.2292 - val_acc: 0.9330\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0440 - acc: 0.9785 - val_loss: 0.2144 - val_acc: 0.9380\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0491 - acc: 0.9780 - val_loss: 0.1898 - val_acc: 0.9410\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.0508 - acc: 0.9810 - val_loss: 0.3125 - val_acc: 0.9200\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.0526 - acc: 0.9815 - val_loss: 0.2536 - val_acc: 0.9260\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.0473 - acc: 0.9840 - val_loss: 0.2529 - val_acc: 0.9260\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.0620 - acc: 0.9765 - val_loss: 0.2163 - val_acc: 0.9320\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0598 - acc: 0.9760 - val_loss: 0.2250 - val_acc: 0.9300\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.0475 - acc: 0.9840 - val_loss: 0.2298 - val_acc: 0.9380\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0452 - acc: 0.9830 - val_loss: 0.2294 - val_acc: 0.9350\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.0339 - acc: 0.9870 - val_loss: 0.2834 - val_acc: 0.9280\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0470 - acc: 0.9825 - val_loss: 0.2173 - val_acc: 0.9310\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.0328 - acc: 0.9860 - val_loss: 0.2336 - val_acc: 0.9300\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0462 - acc: 0.9800 - val_loss: 0.2602 - val_acc: 0.9330\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.0334 - acc: 0.9880 - val_loss: 0.2759 - val_acc: 0.9330\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0366 - acc: 0.9880 - val_loss: 0.2565 - val_acc: 0.9310\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0377 - acc: 0.9880 - val_loss: 0.2720 - val_acc: 0.9180\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0412 - acc: 0.9855 - val_loss: 0.3652 - val_acc: 0.9180\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.0386 - acc: 0.9840 - val_loss: 0.2541 - val_acc: 0.9310\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.0374 - acc: 0.9880 - val_loss: 0.2734 - val_acc: 0.9290\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0291 - acc: 0.9910 - val_loss: 0.2224 - val_acc: 0.9340\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0286 - acc: 0.9895 - val_loss: 0.2616 - val_acc: 0.9320\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.0277 - acc: 0.9870 - val_loss: 0.3068 - val_acc: 0.9290\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0378 - acc: 0.9865 - val_loss: 0.5097 - val_acc: 0.9110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0458 - acc: 0.9835 - val_loss: 0.3118 - val_acc: 0.9270\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.0307 - acc: 0.9875 - val_loss: 0.3288 - val_acc: 0.9220\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0279 - acc: 0.9895 - val_loss: 0.2248 - val_acc: 0.9370\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.0265 - acc: 0.9905 - val_loss: 0.2447 - val_acc: 0.9360\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0244 - acc: 0.9905 - val_loss: 0.2936 - val_acc: 0.9270\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0321 - acc: 0.9875 - val_loss: 0.2724 - val_acc: 0.9300\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0290 - acc: 0.9880 - val_loss: 0.2582 - val_acc: 0.9280\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0250 - acc: 0.9905 - val_loss: 0.2794 - val_acc: 0.9260\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0215 - acc: 0.9925 - val_loss: 0.2880 - val_acc: 0.9340\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0372 - acc: 0.9850 - val_loss: 0.2670 - val_acc: 0.9290\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.0236 - acc: 0.9915 - val_loss: 0.5302 - val_acc: 0.9060\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.0329 - acc: 0.9885 - val_loss: 0.3096 - val_acc: 0.9290\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.0256 - acc: 0.9895 - val_loss: 0.2905 - val_acc: 0.9310\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.0361 - acc: 0.9900 - val_loss: 0.2523 - val_acc: 0.9320\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0222 - acc: 0.9915 - val_loss: 0.2630 - val_acc: 0.9370\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.0298 - acc: 0.9890 - val_loss: 0.2323 - val_acc: 0.9350\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.0211 - acc: 0.9915 - val_loss: 0.3700 - val_acc: 0.9210\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.0265 - acc: 0.9900 - val_loss: 0.3065 - val_acc: 0.9250\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0237 - acc: 0.9895 - val_loss: 0.2399 - val_acc: 0.9380\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.0241 - acc: 0.9925 - val_loss: 0.2470 - val_acc: 0.9430\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0226 - acc: 0.9940 - val_loss: 0.2529 - val_acc: 0.9400\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.0310 - acc: 0.9905 - val_loss: 0.2808 - val_acc: 0.9400\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.0190 - acc: 0.9930 - val_loss: 0.3943 - val_acc: 0.9220\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0186 - acc: 0.9920 - val_loss: 0.3464 - val_acc: 0.9340\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0235 - acc: 0.9925 - val_loss: 0.3212 - val_acc: 0.9230\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0266 - acc: 0.9895 - val_loss: 0.3070 - val_acc: 0.9370\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0200 - acc: 0.9940 - val_loss: 0.2988 - val_acc: 0.9320\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0283 - acc: 0.9920 - val_loss: 0.2835 - val_acc: 0.9310\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.0164 - acc: 0.9945 - val_loss: 0.3271 - val_acc: 0.9340\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0186 - acc: 0.9945 - val_loss: 0.3191 - val_acc: 0.9270\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0196 - acc: 0.9935 - val_loss: 0.2990 - val_acc: 0.9380\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.0184 - acc: 0.9950 - val_loss: 0.2739 - val_acc: 0.9380\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.0185 - acc: 0.9935 - val_loss: 0.2848 - val_acc: 0.9400\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0208 - acc: 0.9900 - val_loss: 0.2306 - val_acc: 0.9450\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0180 - acc: 0.9950 - val_loss: 0.3074 - val_acc: 0.9320\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.0191 - acc: 0.9935 - val_loss: 0.3492 - val_acc: 0.9310\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.0208 - acc: 0.9930 - val_loss: 0.5140 - val_acc: 0.9170\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.0142 - acc: 0.9940 - val_loss: 0.2850 - val_acc: 0.9410\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.0193 - acc: 0.9915 - val_loss: 0.3733 - val_acc: 0.9310\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.0259 - acc: 0.9925 - val_loss: 0.2827 - val_acc: 0.9410\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "              metrics=['acc'])\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=100,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting model training results\n",
    "utility_obj.plot_training_history(history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from IPython.display import display, Markdown #just to display markdown\n",
    "\n",
    "# keras imports\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "# visualiaztion imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# general imports\n",
    "import numpy as np  #for vector operation\n",
    "import string   # provides strings variations for character embedding\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## samples texts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['The cat sat on the mat', ' The dog ate my homework']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"## samples texts\"))\n",
    "\n",
    "#creating sample text\n",
    "samples = [\"The cat sat on the mat\", \" The dog ate my homework\"] \n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## word level one hot encoding"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting to create token_index for every distinct vocabulary\n",
      "token_index created.\n",
      "\n",
      "\n",
      "Starting to create sentence vector using token_index\n",
      "sentences vectorised.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### created word index's for sentence encoding"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 1, 'cat': 2, 'sat': 3, 'on': 4, 'the': 5, 'mat': 6, 'dog': 7, 'ate': 8, 'my': 9, 'homework': 10}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Result"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape (2, 11)\n",
      "# sample:2,  specified max length:2,  # vocabulary:11\n",
      "\n",
      "[[0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1.]]\n",
      "\n",
      "Note:  In the final result, index of each element in the vectors denotes the eoncoding of the words.\n",
      "       \"0\"/\"1\" denote presence of a vocabulary\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"## word level one hot encoding\"))\n",
    "\n",
    "#initializing word-encoding dictionary\n",
    "token_index = {} \n",
    "\n",
    "def word_one_hot_embeddings(text_samples,max_sentence_length=8):\n",
    "    \"\"\"\n",
    "        # Creating sentence vectors by represent each word as a vector\n",
    "        # word as a vector: vector of length of vocabulary, with \"1\" for that specified word and zero elsewhere\n",
    "    \"\"\"\n",
    "\n",
    "    # Encoding words in the corpus\n",
    "    print(\"\\nStarting to create token_index for every distinct vocabulary\")\n",
    "    for sample in text_samples:\n",
    "        for word in sample.split():\n",
    "            if word not in token_index.keys():\n",
    "                token_index[word] = len(token_index) + 1\n",
    "    print(\"token_index created.\\n\")\n",
    "\n",
    "    # Word level one hot encoding\n",
    "    print(\"\\nStarting to create sentence vector using token_index\")\n",
    "    results = np.zeros(shape=(len(text_samples),len(token_index)+1))\n",
    "    for i , sample in enumerate(text_samples):\n",
    "        for j , word in enumerate(sample.split()):\n",
    "            index_ = token_index[word]\n",
    "            results[i,index_] = 1\n",
    "    print(\"sentences vectorised.\\n\")\n",
    "    return (results)\n",
    "\n",
    "word_level_vectorised_sample = word_one_hot_embeddings(text_samples=samples,max_sentence_length=8)\n",
    "shape = (word_level_vectorised_sample.shape)\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"### created word index's for sentence encoding\"))\n",
    "print (token_index)\n",
    "\n",
    "display(Markdown(\"### Result\"))\n",
    "print(\"Output shape {}\".format(word_level_vectorised_sample.shape))\n",
    "print(\"# sample:{},  specified max length:{},  # vocabulary:{}\\n\".format(len(samples),shape[0],shape[1]))\n",
    "print(word_level_vectorised_sample)\n",
    "\n",
    "print(\n",
    "\"\"\"\n",
    "Note:  In the final result, index of each element in the vectors denotes the eoncoding of the words.\n",
    "       \"0\"/\"1\" denote presence of a vocabulary\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## word level one hot encoding - KERAS"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sentence encoding results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### created word index's for sentence encoding"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'cat': 2, 'sat': 3, 'on': 4, 'mat': 5, 'dog': 6, 'ate': 7, 'my': 8, 'homework': 9}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Result"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape (2, 10)\n",
      "# sample:2,  specified max length:2,  # vocabulary:10\n",
      "\n",
      "[[0. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 1. 1. 1. 1.]]\n",
      "\n",
      "Note:  In the final result, index of each element in the vectors denotes the eoncoding of the words.\n",
      "       \"0\"/\"1\" denote presence of a vocabulary\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"## word level one hot encoding - KERAS\"))\n",
    "# One-hot encoding using keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=len (token_index))\n",
    "tokenizer.fit_on_texts(samples)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(samples) # sentence encoding\n",
    "one_hot_results = tokenizer.texts_to_matrix(samples,mode='binary') # creating one hot results\n",
    "shape = (one_hot_results.shape)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "one_hot_results\n",
    "\n",
    "display(Markdown(\"### sentence encoding results\"))\n",
    "print (sequences)\n",
    "display(Markdown(\"### created word index's for sentence encoding\"))\n",
    "print (word_index)\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"### Result\"))\n",
    "print(\"Output shape {}\".format(one_hot_results.shape))\n",
    "print(\"# sample:{},  specified max length:{},  # vocabulary:{}\\n\".format(len(samples),shape[0],shape[1]))\n",
    "print (one_hot_results)\n",
    "\n",
    "print(\n",
    "\"\"\"\n",
    "Note:  In the final result, index of each element in the vectors denotes the eoncoding of the words.\n",
    "       \"0\"/\"1\" denote presence of a vocabulary\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## character level one hot encoding"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### characters used for encoding"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 distinct character vocab present\n",
      "Character level indexing\n",
      "{'0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, 'a': 11, 'b': 12, 'c': 13, 'd': 14, 'e': 15, 'f': 16, 'g': 17, 'h': 18, 'i': 19, 'j': 20, 'k': 21, 'l': 22, 'm': 23, 'n': 24, 'o': 25, 'p': 26, 'q': 27, 'r': 28, 's': 29, 't': 30, 'u': 31, 'v': 32, 'w': 33, 'x': 34, 'y': 35, 'z': 36, 'A': 37, 'B': 38, 'C': 39, 'D': 40, 'E': 41, 'F': 42, 'G': 43, 'H': 44, 'I': 45, 'J': 46, 'K': 47, 'L': 48, 'M': 49, 'N': 50, 'O': 51, 'P': 52, 'Q': 53, 'R': 54, 'S': 55, 'T': 56, 'U': 57, 'V': 58, 'W': 59, 'X': 60, 'Y': 61, 'Z': 62, '!': 63, '\"': 64, '#': 65, '$': 66, '%': 67, '&': 68, \"'\": 69, '(': 70, ')': 71, '*': 72, '+': 73, ',': 74, '-': 75, '.': 76, '/': 77, ':': 78, ';': 79, '<': 80, '=': 81, '>': 82, '?': 83, '@': 84, '[': 85, '\\\\': 86, ']': 87, '^': 88, '_': 89, '`': 90, '{': 91, '|': 92, '}': 93, '~': 94, ' ': 95, '\\t': 96, '\\n': 97, '\\r': 98, '\\x0b': 99, '\\x0c': 100} \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Result"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape (2, 30, 101)\n",
      "# sample:2,  specified max length:30,  # vocabulary:101\n",
      "\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"## character level one hot encoding\"))\n",
    "\n",
    "def character_one_hot_embeddings(characters,max_sentence_length_in_characters=30):\n",
    "    \"\"\"\n",
    "        # Creating sentence vectors by using character level encoding\n",
    "    \"\"\"\n",
    "    character_index =  dict(zip(characters,(range(1,len(characters)+1))))\n",
    "    results = np.zeros(shape=(len(samples),max_sentence_length_in_characters,len(characters)+1))\n",
    "\n",
    "    for i , sample in enumerate(samples):\n",
    "        #print (sample)\n",
    "        for j , character in enumerate(sample):\n",
    "            #print (i,j,character_index.get(character),character)\n",
    "            results[i,j,character_index.get(character)] = 1\n",
    "    return (results,character_index)\n",
    "            \n",
    "characters = string.printable\n",
    "char_level_vectorised_sample, character_index = character_one_hot_embeddings(characters)\n",
    "shape = (char_level_vectorised_sample.shape)\n",
    "\n",
    "display(Markdown(\"### characters used for encoding\"))\n",
    "print (\"{} distinct character vocab present\".format(len(characters)))\n",
    "print (\"Character level indexing\")\n",
    "print(character_index,\"\\n\")\n",
    "\n",
    "\n",
    "display(Markdown(\"### Result\"))\n",
    "print(\"Output shape {}\".format(char_level_vectorised_sample.shape))\n",
    "print(\"# sample:{},  specified max length:{},  # vocabulary:{}\\n\".format(shape[0],shape[1],shape[2]))\n",
    "print(char_level_vectorised_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## word level one hot encoding using hasing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Result"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 1., 1., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 1., 0., 1., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(\"## word level one hot encoding using hashing\"))\n",
    "dimensionality = len(token_index)\n",
    "max_length = 10\n",
    "\n",
    "results = np.zeros((len(samples),dimensionality))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index= abs(hash(word)% dimensionality)\n",
    "        results[i, index] =1\n",
    "        \n",
    "display(Markdown(\"### Result\"))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Understanding word embedding with embedding layer"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### imdb dataset preparation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data\n",
      "\n",
      "Raw text [\"Working with one of the best Shakespeare sources, this film manages to be creditable to it's source, whilst still appealing to a wider audience.<br /><br />Branagh steals the film from under Fishburne's nose, and there's a talented cast on good form.\", 'Well...tremors I, the original started off in 1990 and i found the movie quite enjoyable to watch. however, they proceeded to make tremors II and III. Trust me, those movies started going downhill right after they finished the first one, i mean, ass blasters??? Now, only God himself is capable of answering the question \"why in Gods name would they create another one of these dumpster dives of a movie?\" Tremors IV cannot be considered a bad movie, in fact it cannot be even considered an epitome of a bad movie, for it lives up to more than that. As i attempted to sit though it, i noticed that my eyes started to bleed, and i hoped profusely that the little girl from the ring would crawl through the TV and kill me. did they really think that dressing the people who had stared in the other movies up as though they we\\'re from the wild west would make the movie (with the exact same occurrences) any better? honestly, i would never suggest buying this movie, i mean, there are cheaper ways to find things that burn well.']\n",
      "\n",
      "text labels [0, 0]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### creating word embedding on imdb dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88582 unique token.\n",
      "\n",
      "After data preprocessing\n",
      " # Training samples 200, # Testing samples 10000\n",
      "\n",
      "Word encoded imdb review data\n",
      "[[   1  545  136   68   84  444    1  152    2 5958    2   86   33 4238\n",
      "     1  662   20   65  496    9   13    1  274   12   10 1798   10   13\n",
      "   682   12    9   13  699   18  150  142   18    5 2107   29   12   93\n",
      "    40    5  377  117   23   22 3990   69   81   12 5081   15   65   52\n",
      "  2010    2  277   33   76    5 5400   33 7257 2128   54   93  249   33\n",
      "    68 1885 2297    2 1643   18   12    6  117   33   67  409   37 1706\n",
      "   171   33   61   25   28   49 1037   48   23   33  167    5   78   51\n",
      "   291   44]\n",
      " [5970 2559    6  774    8   11 1853  353   11   19    6   52 1910   19\n",
      "    12 4059 6130   20    1  153  673  206 5970 2559  304 7040 7176    2\n",
      "     3  168  405   11   19   97   25   74    3 1686    9    6   21  207\n",
      "    70  321    2   30  208   44   46   52 2025  225   12  494    5 1144\n",
      "     3 1307    1 2172   37  225   30    1 1758  545   18    1  113    9\n",
      "     1  106 1604    6  639   16   24 3730  793   18   26 3208   70   80\n",
      "     3   50 2700   70 5723  106   14   26 2269    5  409   31   24  202\n",
      "   875   77]]\n",
      "\n",
      "Imdb review data lables\n",
      "[0 1]\n",
      "\n",
      "Note:  \n",
      "0 : \"Negative review\"\n",
      "1 : \"Positive review\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"## Understanding word embedding with embedding layer\"))\n",
    "display(Markdown(\"### imdb dataset preparation\"))\n",
    "\n",
    "# loading the IMDB dataset\n",
    "\n",
    "# download the dataset from \"ai.stanford.edu/~amaas/data/sentiment/\" \n",
    "# extract the dataset \n",
    "\n",
    "imdb_dir = \"./aclImdb\" # actual path to imdb dataset folder\n",
    "train_dir = os.path.join(imdb_dir,\"train\")\n",
    "\n",
    "\n",
    "# collecting text from each file \n",
    "# collecting corresponding text labels\n",
    "labels = []\n",
    "texts = []\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(train_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "         if fname[-4:] == '.txt':\n",
    "                f = open(os.path.join(dir_name, fname))\n",
    "                texts.append(f.read())\n",
    "                f.close()\n",
    "                if label_type == 'neg':\n",
    "                    labels.append(0)\n",
    "                else:\n",
    "                    labels.append(1)\n",
    "\n",
    "print (\"Raw data\\n\")\n",
    "\n",
    "print (\"Raw text {}\\n\".format(texts[:2]))\n",
    "print (\"text labels {}\\n\".format(labels[:2]))\n",
    "\n",
    "display(Markdown(\"### creating word embedding on imdb dataset\"))\n",
    "\n",
    "\n",
    "# pre-processing initiation's\n",
    "n_vocab = 10000 # max number of distinct vocabulary (top 10,000)\n",
    "max_sentence_length = 100  # Cuts a review after 100 words\n",
    "training_samples = 200 # number of training examples\n",
    "validation_samples = 10000 # number of validation examples\n",
    "\n",
    "# pre-processing dataset\n",
    "\n",
    "# starting to create word emdedding\n",
    "\n",
    "# building tokenizer (keras object that holds index_to_word dictionary, n_vocab, etc parameters)\n",
    "tokenizer = Tokenizer(num_words=n_vocab)\n",
    "tokenizer.fit_on_texts(texts) # feeding the text data to tokenizer\n",
    "\n",
    "# creating word vectors using keras tokenizer & cutting each sentence after 100 words\n",
    "sequences = tokenizer.texts_to_sequences(texts) \n",
    "sequences_padded = pad_sequences(sequences,maxlen=max_sentence_length,\n",
    "                                padding='post', truncating='post') # default paddind is \"pre\" in keras\n",
    "word_index = tokenizer.word_index # word_to_index mappind dictionary\n",
    "\n",
    "print (\"Found {} unique token.\\n\".format(len(word_index)) )\n",
    "\n",
    "# training and testind data split\n",
    "indices = np.arange(sequences_padded.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "sequences_padded = sequences_padded[indices]\n",
    "labels = np.asarray(labels)[indices]\n",
    "x_train = sequences_padded[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = sequences_padded[training_samples: training_samples + validation_samples]\n",
    "y_val = labels[training_samples: training_samples + validation_samples]\n",
    "\n",
    "print (\"After data preprocessing\")\n",
    "print(\" # Training samples {}, # Testing samples {}\\n\".format(x_train.shape[0],x_val.shape[0]))\n",
    "print(\"Word encoded imdb review data\")\n",
    "print(x_train[:2])\n",
    "\n",
    "print(\"\\nImdb review data lables\")\n",
    "print(y_train[:2])\n",
    "print(\n",
    "\"\"\"\n",
    "Note:  \n",
    "0 : \"Negative review\"\n",
    "1 : \"Positive review\"\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_model_training_history(history):\n",
    "    \n",
    "    #collecting all post-training values \n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    \n",
    "    # ploting accuracies\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    # ploting losses\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### building a sequential model using embedding layer"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 801       \n",
      "=================================================================\n",
      "Total params: 80,801\n",
      "Trainable params: 80,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6925 - acc: 0.5400 - val_loss: 0.6928 - val_acc: 0.5132\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6682 - acc: 0.8850 - val_loss: 0.6926 - val_acc: 0.5154\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6508 - acc: 0.9550 - val_loss: 0.6924 - val_acc: 0.5182\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6338 - acc: 0.9900 - val_loss: 0.6922 - val_acc: 0.5195\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6160 - acc: 0.9900 - val_loss: 0.6919 - val_acc: 0.5210\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5970 - acc: 0.9900 - val_loss: 0.6918 - val_acc: 0.5229\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5768 - acc: 1.0000 - val_loss: 0.6916 - val_acc: 0.5188\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5553 - acc: 0.9950 - val_loss: 0.6914 - val_acc: 0.5197\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5324 - acc: 1.0000 - val_loss: 0.6911 - val_acc: 0.5206\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5083 - acc: 1.0000 - val_loss: 0.6908 - val_acc: 0.5209\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x183ec9c748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1838a46f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"### building a sequential model using embedding layer\"))\n",
    "\n",
    "#embedding layer initializations\n",
    "n_vocab_embedding_layer = n_vocab\n",
    "size_of_word_vector = 8\n",
    "\n",
    "## Embedding layer is trainable layer. It is best understood as a dictionary \n",
    "## that maps integer indices (which stands for specific words) to a dense vectors\n",
    "\n",
    "# Creating a 1 layer neural network\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_vocab_embedding_layer,size_of_word_vector,input_length=max_sentence_length)) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics=[\"acc\"])\n",
    "model.summary()\n",
    "\n",
    "# Starting model training\n",
    "history = model.fit(x_train,y_train,\n",
    "                   epochs = 10,\n",
    "                    batch_size = 32,\n",
    "                    validation_data=(x_val,y_val)\n",
    "                   )\n",
    "\n",
    "# ploting model training results\n",
    "plot_model_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

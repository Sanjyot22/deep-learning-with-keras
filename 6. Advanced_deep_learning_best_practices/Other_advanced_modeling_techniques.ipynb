{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADVANCED MODEL DEVELOPMENT TECHNIQUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "### Normal normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = (data - np.mean(data, axis=...)) / np.std(data, axis=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After a Conv layer:\n",
    "conv_model.add(layers.Conv2D(32, 3, activation='relu'))\n",
    "conv_model.add(layers.BatchNormalization())\n",
    "# After a Dense layer:\n",
    "dense_model.add(layers.Dense(32, activation='relu'))\n",
    "dense_model.add(layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A small depthwise separable convnet\n",
    "\n",
    "\"depthwise separable convnet layer\" can used as a drop-in replacement for Conv2D, that will make your model lighter (fewer trainable weight parameters), faster (fewer floating point operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SeparableConv2D(32, activation='relu', input_shape=(height, width, channels)))\n",
    "model.add(SeparableConv2D(64, activation='relu'))\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(SeparableConv2D(64, activation='relu'))\n",
    "model.add(SeparableConv2D(128, activation='relu'))\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(SeparableConv2D(64, activation='relu'))\n",
    "model.add(SeparableConv2D(128, activation='relu'))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model ensembling via a weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_a = model_a.predict(x_val)\n",
    "preds_b = model_b.predict(x_val)\n",
    "preds_c = model_c.predict(x_val)\n",
    "preds_d = model_d.predict(x_val)\n",
    "# These weights (0.5, 0.25, 0.1, 0.15) are assumed\n",
    "# to be learned empirically.\n",
    "final_preds = 0.5 * preds_a + 0.25 * preds_b + 0.1 * preds_c + 0.15 * preds_d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

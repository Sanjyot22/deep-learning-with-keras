{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "# keras imports\n",
    "from keras.layers import Embedding, SimpleRNN, Flatten, Dense\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "import keras\n",
    "import os\n",
    "\n",
    "# general imports\n",
    "from IPython.display import display, Markdown #just to display markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## USING IMDB DATA FOR MODEL TRAINING "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "after data preprocessing\n",
      "input_train shape: (25000, 50)\n",
      "input_test shape: (25000, 50) \n",
      "\n",
      "\n",
      "Imdb review 1 sample input data\n",
      "\n",
      "[[2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
      "    26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
      "     4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
      "   103   32   15   16 5345   19  178   32]]\n",
      "\n",
      "Imdb review data lables\n",
      "[1 0]\n",
      "\n",
      "Note:  \n",
      "0 : \"Negative review\"\n",
      "1 : \"Positive review\"\n",
      "post_padding in input data helps gragient in LSTM flow better \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"## USING IMDB DATA FOR MODEL TRAINING \"))\n",
    "\n",
    "# pre-processing initializations\n",
    "max_features = 10000  # number of words to consider as features\n",
    "maxlen = 50  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "# data pre-prcessing\n",
    "### IMDB data preparation was extensively cover in \"text_pre-processing_basic model_building\"(earlier module) ###\n",
    "\n",
    "\n",
    "print('Loading data...')\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# cutting sentences to max length of 50\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n",
    "\n",
    "print (\"after data preprocessing\")\n",
    "print('input_train shape:', input_train.shape)\n",
    "print('input_test shape:', input_test.shape, \"\\n\")\n",
    "\n",
    "print(\"\\nImdb review 1 sample input data\\n\")\n",
    "print(input_train[:1]) \n",
    "\n",
    "print(\"\\nImdb review data lables\")\n",
    "print(y_train[:2])\n",
    "print(\n",
    "\"\"\"\n",
    "Note:  \n",
    "0 : \"Negative review\"\n",
    "1 : \"Positive review\"\n",
    "post_padding in input data helps gragient in LSTM flow better \n",
    "\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.callbacks.CSVLogger"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.callbacks.ModelCheckpoint\n",
    "keras.callbacks.EarlyStopping\n",
    "keras.callbacks.LearningRateScheduler\n",
    "keras.callbacks.ReduceLROnPlateau\n",
    "keras.callbacks.CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## CALLING ALL THE PRE-DEFINED CALLBACKS FOR MODEL TRAINING"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"## CALLING ALL THE PRE-DEFINED CALLBACKS FOR MODEL TRAINING\"))\n",
    "\n",
    "# This callback will save all the training logs in a file after every epoch\n",
    "dir_path = \"./\"\n",
    "csv_logger = keras.callbacks.CSVLogger(\n",
    "    # This is the path to the file where logs data will be stored\n",
    "    os.path.join(dir_path,\"training.log\")\n",
    ")\n",
    "\n",
    "\n",
    "# This callback will interrupt training when we have stopped improving\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    # This callback will monitor the validation accuracy of the model\n",
    "    monitor='acc',\n",
    "    # Training will be interrupted when the accuracy\n",
    "    # has stopped improving for *more* than 3 epochs\n",
    "    patience=4,\n",
    ")\n",
    "\n",
    "# This callback will save the current weights after every epoch\n",
    "# The name of weight file contains epoch number, val accuracy\n",
    "file_path=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoints = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=file_path,  # Path to the destination model file\n",
    "        # The two arguments below mean that we will not overwrite the\n",
    "        # model file unless `val_loss` has improved, which\n",
    "        # allows us to keep the best model every seen during training.\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "    )\n",
    "\n",
    "reduce_learning_rate = keras.callbacks.ReduceLROnPlateau(\n",
    "    # This callback will monitor the validation loss of the model\n",
    "    monitor='val_loss',\n",
    "    # It will divide the learning by 10 when it gets triggered\n",
    "    factor=0.1,\n",
    "    # It will get triggered after the validation loss has stopped improving\n",
    "    # for at least 3 epochs\n",
    "    patience=3,\n",
    "    # Note that since the callback will be monitor validation loss,\n",
    "    # we need to pass some `validation_data` to our call to `fit`.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## WRITING A CUSTOM CALLING FOR TEST EVALUATION DURING TRAINING"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is a simple example of a custom callback, where we save to disk (as Numpy arrays) \n",
      "the activations of every layer of the model at the end of every epoch, computed on the \n",
      "first sample of the validation set.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"## WRITING A CUSTOM CALLING FOR TEST EVALUATION DURING TRAINING\"))\n",
    "\n",
    "# Called at the start of every epoch\n",
    "# -->on_epoch_begin\n",
    "\n",
    "# Called at the end of every epoch\n",
    "# -->on_epoch_end\n",
    "\n",
    "# Called right before processing each batch\n",
    "# -->on_batch_begin\n",
    "\n",
    "# Called right after processing each batch\n",
    "# -->on_batch_end\n",
    "\n",
    "# Called at the start of training\n",
    "# -->on_train_begin\n",
    "\n",
    "# Called at the end of training\n",
    "# -->on_train_end\n",
    "\n",
    "class TestAccuracyCalculator(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, test_data=None,test_lables=None):\n",
    "        # Passing test data separately\n",
    "        # to test accuracy changes while training\n",
    "        self.test_data = test_data\n",
    "        self.test_lables = test_lables\n",
    "        \n",
    "    def set_model(self, model):\n",
    "        # This method is called by the parent model\n",
    "        # before training, to inform the callback\n",
    "        # of what model will be calling it\n",
    "        self.model = model\n",
    "    \n",
    "    def calculate_binary_accuracy(self):\n",
    "        pass\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "    \n",
    "        if (type(self.test_data) !=  type(None)) and (type(self.test_lables) !=  type(None)):\n",
    "            # Using current best weight from this epoch\n",
    "            # to test on provided test data-set\n",
    "            y_pred = self.model.predict(self.test_data)\n",
    "            y_pred_ = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "\n",
    "            # Accuracy calculation for binary predictions\n",
    "#             accuracy = (K.mean(K.equal(self.test_lables, K.round(y_pred))))\n",
    "            accuracy = np.sum(self.test_lables == y_pred_)\n",
    "            print (y_pred_.shape)\n",
    "            print (accuracy)\n",
    "#             print (\"Test accuracy after {} epocs is {}%\".format(epoch,accuracy))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "test_accuracy_calculator = TestAccuracyCalculator(test_data=input_test, test_lables=y_test)\n",
    "\n",
    "print (\"\"\"\n",
    "Here is a simple example of a custom callback, where we save to disk (as Numpy arrays) \n",
    "the activations of every layer of the model at the end of every epoch, computed on the \n",
    "first sample of the validation set.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks are passed to the model fit the `callbacks` argument in `fit`,\n",
    "# which takes a list of callbacks. You can pass any number of callbacks.\n",
    "callbacks_list = [ csv_logger, early_stopping,\n",
    "                  checkpoints, reduce_learning_rate,\n",
    "                  test_accuracy_calculator\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## TRAINING MODEL WITH CALLBACKS "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model training...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_28 (Embedding)     (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_28 (SimpleRNN)    (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 322,113\n",
      "Trainable params: 322,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 11s 538us/step - loss: 0.5453 - acc: 0.7198 - val_loss: 0.5046 - val_acc: 0.7590\n",
      "(25000, 1)\n",
      "312500000\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 9s 440us/step - loss: 0.3701 - acc: 0.8417 - val_loss: 0.4275 - val_acc: 0.8060\n",
      "(25000, 1)\n",
      "312500000\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 9s 445us/step - loss: 0.2948 - acc: 0.8801 - val_loss: 0.5083 - val_acc: 0.7618\n",
      "(25000, 1)\n",
      "312500000\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 9s 459us/step - loss: 0.2228 - acc: 0.9162 - val_loss: 0.5180 - val_acc: 0.7880\n",
      "(25000, 1)\n",
      "312500000\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 9s 464us/step - loss: 0.1485 - acc: 0.9493 - val_loss: 0.5737 - val_acc: 0.7738\n",
      "(25000, 1)\n",
      "312500000\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 13s 674us/step - loss: 0.0661 - acc: 0.9837 - val_loss: 0.5765 - val_acc: 0.7816\n",
      "(25000, 1)\n",
      "312500000\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 8s 420us/step - loss: 0.0541 - acc: 0.9869 - val_loss: 0.6013 - val_acc: 0.7824\n",
      "(25000, 1)\n",
      "312500000\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 10s 517us/step - loss: 0.0464 - acc: 0.9896 - val_loss: 0.6163 - val_acc: 0.7760\n",
      "(25000, 1)\n",
      "312500000\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 9s 436us/step - loss: 0.0391 - acc: 0.9918 - val_loss: 0.6171 - val_acc: 0.7754\n",
      "(25000, 1)\n",
      "312500000\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 10s 516us/step - loss: 0.0383 - acc: 0.9922 - val_loss: 0.6191 - val_acc: 0.7764\n",
      "(25000, 1)\n",
      "312500000\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"## TRAINING MODEL WITH CALLBACKS \"))\n",
    "\n",
    "# model architecture and training\n",
    "print(\"starting model training...\")\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "print (\"\\n\")\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(input_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9*150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTRODUCTION TO TENSORBOARD IN KERAS\n",
    "![title](./pics/tensor-board-intro.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# general imports\n",
    "from IPython.display import display, Markdown #just to display markdown\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# keras imports\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "from keras.layers import Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import imdb\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## USING IMDB DATA FOR MODEL TRAINING "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "after data preprocessing\n",
      "input_train shape: (25000, 50)\n",
      "input_test shape: (25000, 50) \n",
      "\n",
      "\n",
      "Imdb review 1 sample input data\n",
      "\n",
      "[[2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
      "    26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
      "     4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
      "   103   32   15   16 5345   19  178   32]]\n",
      "\n",
      "Imdb review data lables\n",
      "[1 0]\n",
      "\n",
      "Note:  \n",
      "0 : \"Negative review\"\n",
      "1 : \"Positive review\"\n",
      "post_padding in input data helps gragient in LSTM flow better \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"## USING IMDB DATA FOR MODEL TRAINING \"))\n",
    "\n",
    "# pre-processing initializations\n",
    "max_features = 10000  # number of words to consider as features\n",
    "maxlen = 50  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "# data pre-prcessing\n",
    "### IMDB data preparation was extensively cover in \"text_pre-processing_basic model_building\"(earlier module) ###\n",
    "\n",
    "print('Loading data...')\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# cutting sentences to max length of 50\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n",
    "\n",
    "print (\"after data preprocessing\")\n",
    "print('input_train shape:', input_train.shape)\n",
    "print('input_test shape:', input_test.shape, \"\\n\")\n",
    "\n",
    "print(\"\\nImdb review 1 sample input data\\n\")\n",
    "print(input_train[:1]) \n",
    "\n",
    "print(\"\\nImdb review data lables\")\n",
    "print(y_train[:2])\n",
    "print(\n",
    "\"\"\"\n",
    "Note:  \n",
    "0 : \"Negative review\"\n",
    "1 : \"Positive review\"\n",
    "post_padding in input data helps gragient in LSTM flow better \n",
    "\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRITING TENSORBOARD CALLBACKS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = keras.callbacks.TensorBoard(\n",
    "        # Log files will be written at this location\n",
    "        # make sure that this folder is already present in training dir \n",
    "        # or change the path to concerned folder\n",
    "        log_dir='my_log_dir',\n",
    "        #We will record activation histograms every 1 epoch\n",
    "        #histogram_freq=1,\n",
    "        batch_size=128,\n",
    "        embeddings_freq=1,\n",
    "        embeddings_layer_names = [\"embed\"],\n",
    "        embeddings_metadata='metadata.tsv',\n",
    "        # We will record embedding data every 1 epoch\n",
    "        #embeddings_freq=1,\n",
    "        embeddings_data=input_test\n",
    ")\n",
    "\n",
    "log_dir = './my_log_dir'\n",
    "if not os.path.exists(log_dir):\n",
    "    makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f my_log_dir/* # clear the tensorboard log folder\n",
    "# save class labels to disk to color data points in TensorBoard accordingly\n",
    "with open(os.path.join(\"my_log_dir\", 'metadata.tsv'), 'w') as f:\n",
    "    np.savetxt(f, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING MODEL WITH TENSORBOARD CALLBACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture and training\n",
    "print(\"starting model training...\")\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Embedding(max_features, 128, input_length=maxlen, name='embed'))\n",
    "model.add(keras.layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(1))\n",
    "model.summary()\n",
    "print (\"\\n\")\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(input_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[callbacks_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANING WITH MNIST DATA & TENSORBOARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "after data preprocessing\n",
      "input_train shape: (60000, 28, 28, 1)\n",
      "input_test shape: (10000, 28, 28, 1) \n",
      "\n",
      "\n",
      "Imdb review data lables\n",
      "\n",
      "Before preprocessing\n",
      "[5 0 4 1 9 2 1 3 1 4]\n",
      "\n",
      "After preprocessing(one hot encoded)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# pre-processing initializations\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 # normalizing train images\n",
    "x_test /= 255  # normalizing test images\n",
    "\n",
    "y_ = y_train\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print (\"after data preprocessing\")\n",
    "print('input_train shape:', x_train.shape)\n",
    "print('input_test shape:', x_test.shape, \"\\n\")\n",
    " \n",
    "print(\"\\nImdb review data lables\\n\")\n",
    "\n",
    "\n",
    "print (\"Before preprocessing\")\n",
    "print (y_[:10])\n",
    "print (\"\\nAfter preprocessing(one hot encoded)\")\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRITING TENSORBOARD CALLBACKS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = './my_log_dir'\n",
    "if not os.path.exists(log_dir):\n",
    "    makedirs(log_dir)\n",
    "\n",
    "!rm -f my_log_dir/*\n",
    "# save class labels to disk to color data points in TensorBoard accordingly\n",
    "with open(os.path.join(log_dir, 'metadata.tsv'), 'w') as f:\n",
    "    np.savetxt(f, y_test)\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "                          log_dir=log_dir,\n",
    "                          batch_size=batch_size,\n",
    "                          #histogram_freq=1,\n",
    "                          embeddings_freq=1,\n",
    "                          embeddings_layer_names=['features'], # name of layer @toCalculateActivations\n",
    "                          embeddings_metadata='metadata.tsv',\n",
    "                          embeddings_data=x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING MODEL WITH TENSORBOARD CALLBACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model training...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "features (Dense)             (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.2609 - acc: 0.9192 - val_loss: 0.0551 - val_acc: 0.9825\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 71s 1ms/step - loss: 0.0865 - acc: 0.9737 - val_loss: 0.0400 - val_acc: 0.9859\n",
      "Epoch 3/12\n",
      "42112/60000 [====================>.........] - ETA: 19s - loss: 0.0678 - acc: 0.9797"
     ]
    }
   ],
   "source": [
    "# model architecture and training\n",
    "print(\"starting model training...\")\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu', name='features'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "print (\"\\n\")\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,## WRITING TENSORBOARD CALLBACKS \n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          callbacks=[tensorboard],\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL STYLE TRANSFER\n",
    "![title](./pics/style-transfer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schematic formulation of a \"style transfer\" loss\n",
    "\n",
    "conserve the \"content\" of the original image, while adopting the \"style\" of the reference image. If we were able to mathematically define content and style, then an appropriate loss function to minimize would be the following\n",
    "\n",
    "```\n",
    "loss = distance(style(reference_image) - style(generated_image)) +\n",
    "   distance(content(original_image) - content(generated_image))\n",
    "```\n",
    "\n",
    "\n",
    "- Preserve content by maintaining similar high-level layer activations between the target content image and the generated image. The convnet should \"see\" both the target image and the generated image as \"containing the same things\".\n",
    "\n",
    "- Preserve style by maintaining similar correlations within activations for both low-level layers and high-level layers. Indeed, feature correlations capture textures: the generated and the style reference image should share the same textures at different spatial scales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural style transfer in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "\n",
    "#keras imports\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications import vgg19\n",
    "from keras import backend as K\n",
    "\n",
    "#general imports\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from scipy.misc import imsave\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_height, img_width))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final ouput shape will be: (400, 533, 3)\n"
     ]
    }
   ],
   "source": [
    "# This is the path to the image you want to transform.\n",
    "target_image_path = './pics/target-image.jpg'\n",
    "# This is the path to the style image.\n",
    "style_reference_image_path = './pics/reference-image.jpg'\n",
    "# Dimensions of the generated picture.\n",
    "width, height = load_img(target_image_path).size\n",
    "img_height = 400\n",
    "img_width = int(width * img_height / height)\n",
    "\n",
    "print (\"Final ouput shape will be: {}\".format((img_height,img_width,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the pre-trained VGG19 network and Loss definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The loss that we minimize is a weighted average of these below three losses\n",
    "\n",
    "def content_loss(base, combination):\n",
    "    # The content loss, operating on the features of the \n",
    "    # target image and the generated \"combination\" image\n",
    "    return K.sum(K.square(combination - base))\n",
    "\n",
    "def gram_matrix(x):\n",
    "    # map of the correlations found in the feature matrix\n",
    "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram\n",
    "\n",
    "def style_loss(style, combination):\n",
    "    # The style loss, operating on the features of the style \n",
    "    # reference image and the generated \"combination\" image\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_height * img_width\n",
    "    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n",
    "\n",
    "def total_variation_loss(x):\n",
    "    # The total variation loss, operating on the pixels \n",
    "    # of the generated \"combination\" image\n",
    "    a = K.square(\n",
    "        x[:, :img_height - 1, :img_width - 1, :] - x[:, 1:, :img_width - 1, :])\n",
    "    b = K.square(\n",
    "        x[:, :img_height - 1, :img_width - 1, :] - x[:, :img_height - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))\n",
    "\n",
    "\n",
    "target_image = K.constant(preprocess_image(target_image_path))\n",
    "style_reference_image = K.constant(preprocess_image(style_reference_image_path))\n",
    "\n",
    "# This placeholder will contain our generated image\n",
    "combination_image = K.placeholder((1, img_height, img_width, 3))\n",
    "\n",
    "# We combine the 3 images into a single batch\n",
    "input_tensor = K.concatenate([target_image,\n",
    "                              style_reference_image,\n",
    "                              combination_image], axis=0)\n",
    "\n",
    "# We build the VGG19 network with our batch of 3 images as input.\n",
    "# The model will be loaded with pre-trained ImageNet weights.\n",
    "model = vgg19.VGG19(input_tensor=input_tensor,\n",
    "                    weights='imagenet',\n",
    "                    include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the final loss that we will minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n"
     ]
    }
   ],
   "source": [
    "# Dict mapping layer names to activation tensors\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "\n",
    "# Name of layer used for content loss\n",
    "content_layer = 'block5_conv2'\n",
    "\n",
    "# Name of layers used for style loss\n",
    "style_layers = ['block1_conv1',\n",
    "                'block2_conv1',\n",
    "                'block3_conv1',\n",
    "                'block4_conv1',\n",
    "                'block5_conv1']\n",
    "\n",
    "# Weights in the weighted average of the loss components\n",
    "total_variation_weight = 1e-4\n",
    "style_weight = 1.\n",
    "content_weight = 0.025\n",
    "\n",
    "# Define the loss by adding all components to a `loss` variable\n",
    "loss = K.variable(0.)\n",
    "layer_features = outputs_dict[content_layer]\n",
    "target_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "loss += content_weight * content_loss(target_image_features,\n",
    "                                      combination_features)\n",
    "for layer_name in style_layers:\n",
    "    layer_features = outputs_dict[layer_name]\n",
    "    style_reference_features = layer_features[1, :, :, :]\n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_reference_features, combination_features)\n",
    "    loss += (style_weight / len(style_layers)) * sl\n",
    "loss += total_variation_weight * total_variation_loss(combination_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the gradient descent process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the gradients of the generated image wrt the loss\n",
    "grads = K.gradients(loss, combination_image)[0]\n",
    "\n",
    "# Function to fetch the values of the current loss and the current gradients\n",
    "fetch_loss_and_grads = K.function([combination_image], [loss, grads])\n",
    "\n",
    "class Evaluator(object):\n",
    " \n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "    \n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        x = x.reshape((1, img_height, img_width, 3))\n",
    "        outs = fetch_loss_and_grads([x])\n",
    "        loss_value = outs[0]\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "    \n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values\n",
    "\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The style transfer loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of iteration 0\n",
      "Current loss value: 785713000.0\n",
      "Image saved as my_result_at_iteration_0.png\n",
      "Iteration 0 completed in 222s\n",
      "Start of iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanjyotzade/anaconda3/envs/francois/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 272375520.0\n",
      "Image saved as my_result_at_iteration_1.png\n",
      "Iteration 1 completed in 225s\n",
      "Start of iteration 2\n",
      "Current loss value: 168216620.0\n",
      "Image saved as my_result_at_iteration_2.png\n",
      "Iteration 2 completed in 218s\n",
      "Start of iteration 3\n",
      "Current loss value: 130612824.0\n",
      "Image saved as my_result_at_iteration_3.png\n",
      "Iteration 3 completed in 220s\n",
      "Start of iteration 4\n",
      "Current loss value: 113099510.0\n",
      "Image saved as my_result_at_iteration_4.png\n",
      "Iteration 4 completed in 223s\n",
      "Start of iteration 5\n",
      "Current loss value: 98599976.0\n",
      "Image saved as my_result_at_iteration_5.png\n",
      "Iteration 5 completed in 225s\n",
      "Start of iteration 6\n",
      "Current loss value: 89026530.0\n",
      "Image saved as my_result_at_iteration_6.png\n",
      "Iteration 6 completed in 221s\n",
      "Start of iteration 7\n",
      "Current loss value: 78742240.0\n",
      "Image saved as my_result_at_iteration_7.png\n",
      "Iteration 7 completed in 223s\n",
      "Start of iteration 8\n",
      "Current loss value: 71442940.0\n",
      "Image saved as my_result_at_iteration_8.png\n",
      "Iteration 8 completed in 232s\n",
      "Start of iteration 9\n",
      "Current loss value: 66479000.0\n",
      "Image saved as my_result_at_iteration_9.png\n",
      "Iteration 9 completed in 232s\n",
      "Start of iteration 10\n",
      "Current loss value: 62767340.0\n",
      "Image saved as my_result_at_iteration_10.png\n",
      "Iteration 10 completed in 227s\n",
      "Start of iteration 11\n",
      "Current loss value: 60230484.0\n",
      "Image saved as my_result_at_iteration_11.png\n",
      "Iteration 11 completed in 226s\n",
      "Start of iteration 12\n",
      "Current loss value: 57874904.0\n",
      "Image saved as my_result_at_iteration_12.png\n",
      "Iteration 12 completed in 227s\n",
      "Start of iteration 13\n",
      "Current loss value: 55303020.0\n",
      "Image saved as my_result_at_iteration_13.png\n",
      "Iteration 13 completed in 227s\n",
      "Start of iteration 14\n",
      "Current loss value: 53049304.0\n",
      "Image saved as my_result_at_iteration_14.png\n",
      "Iteration 14 completed in 230s\n",
      "Start of iteration 15\n",
      "Current loss value: 51148052.0\n",
      "Image saved as my_result_at_iteration_15.png\n",
      "Iteration 15 completed in 226s\n",
      "Start of iteration 16\n",
      "Current loss value: 49512400.0\n",
      "Image saved as my_result_at_iteration_16.png\n",
      "Iteration 16 completed in 229s\n",
      "Start of iteration 17\n",
      "Current loss value: 48152710.0\n",
      "Image saved as my_result_at_iteration_17.png\n",
      "Iteration 17 completed in 227s\n",
      "Start of iteration 18\n",
      "Current loss value: 46825696.0\n",
      "Image saved as my_result_at_iteration_18.png\n",
      "Iteration 18 completed in 232s\n",
      "Start of iteration 19\n",
      "Current loss value: 45438304.0\n",
      "Image saved as my_result_at_iteration_19.png\n",
      "Iteration 19 completed in 229s\n"
     ]
    }
   ],
   "source": [
    "result_prefix = 'my_result'\n",
    "iterations = 20\n",
    "# Run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
    "# so as to minimize the neural style loss.\n",
    "# This is our initial state: the target image.\n",
    "# Note that `scipy.optimize.fmin_l_bfgs_b` can only process flat vectors.\n",
    "x = preprocess_image(target_image_path)\n",
    "x = x.flatten()\n",
    "for i in range(iterations):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x,fprime=evaluator.grads, maxfun=20)\n",
    "    \n",
    "    print('Current loss value:', min_val)\n",
    "    \n",
    "    # Save current generated image\n",
    "    img = x.copy().reshape((img_height, img_width, 3))\n",
    "    img = deprocess_image(img)\n",
    "    fname = result_prefix + '_at_iteration_%d.png' % i\n",
    "    imsave(os.path.join(\"pics\",fname), img)\n",
    "    end_time = time.time()\n",
    "    print('Image saved as', fname)\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
